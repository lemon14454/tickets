http {
    limit_req_zone $binary_remote_addr zone=reqlimit:1m rate=10r/s;
    # server save 1mb records of ip
    # N request every second

    upstream backend {
        # no load balance needed for now
        server api:8080;
    }

    server {
        listen 8081;
        # limit_req zone=reqlimit; # basic setup

        # limit_req zone=reqlimit burst=20; # >> a buffer with size of 20

        # burst: Nginx tracks rate limit in 100ms unit, so if rate limit is 10r/s => 1r/100ms.
        # If second request arrive in 100ms, it will return 503, that's usually not what we want.
        # We can setup burst as a queue, if the second request arrive within 100ms, it will be sent to burst queue
        # Nginx will consume it with the rate of 1r/100ms, if the queue is full, request that come after will 503

        limit_req zone=reqlimit burst=20 nodelay; #  >> additional nodelay parameter

        # nodelay: in the same situation, second request arrive in 100ms, it will take the burst queue space,
        # and consume it immediately instead of waiting in queue, the space taken by the request won't release
        # until the original rate limit time passed (1r/100ms).

        location / {
            proxy_pass http://backend/;
        }
    }

}

events {}
